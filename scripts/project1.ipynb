{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "from implementations import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TRAIN_PATH = '../data/train.csv/train.csv' # TODO: download train data and supply path here \n",
    "y, x, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "y[y<0] = 0"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Cleanning dataset by deleting index where there is outsider (values -999.0):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "selector = np.all(x != -999.0, axis=1)\n",
    "x_clean = x[selector]\n",
    "y_clean = y[selector]\n",
    "\n",
    "print(x.shape)\n",
    "print(x_clean.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Too many data lost in tX_clean, maybe we can make calculation without taking into account the -999.0 in the average\n",
    "We can replace this value by NaN wich will be not taking into account during the standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.56765498468643\n"
     ]
    }
   ],
   "source": [
    "def standardize_NAN(tX):\n",
    "    tX_nan = tX.copy()\n",
    "    for i in range(tX.shape[0]):\n",
    "        for j in range(tX.shape[1]):\n",
    "            if (tX_nan[i,j] == -999.0):\n",
    "                tX_nan[i,j] = np.nan\n",
    "    return (standardize(tX_nan))\n",
    "\n",
    "\n",
    "# Tout les nans (correspondant a des valeurs non connues) sont remplacÃ©s par la moyenne de la colonnes\n",
    "def replace_mean(tX_nan):\n",
    "    means_cols = np.nanmean(tX_nan,axis=1)\n",
    "    for row in range(0,tX_nan.shape[0]):\n",
    "        for col in range(0,tX_nan.shape[1]):\n",
    "            if np.isnan(tX_nan[row,col]):\n",
    "                tX_nan[row,col]=means_cols[col]\n",
    "    return (tX_nan)\n",
    "\n",
    "x_nan, mean_x_nan, std_x_nan = standardize_NAN(x)\n",
    "x_nan = replace_mean(x_nan)\n",
    "\n",
    "def get_ind_percentiles(tX, tX_clean, i, percentile):\n",
    "    arguments = []\n",
    "    a = np.percentile(tX_clean[:,i],percentile)\n",
    "    tX_perc = tX.copy()\n",
    "    arguments = np.argwhere(tX_perc[tX[:,i] > round(a, 2)])\n",
    "    return list(set(arguments[:,0]))\n",
    "\n",
    "def remove_rows_by_percentiles(tX,tX_clean):\n",
    "    args = []\n",
    "    for i in range(tX.shape[1]):\n",
    "        args= args+get_ind_percentiles(tX,tX_clean,i,99.97)\n",
    "    flat_list = [item for item in args]\n",
    "    mylist = list(set(flat_list))\n",
    "    return mylist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subgroup Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.83469273209879\n",
      "63.38124719688545\n",
      "129.81575662840595\n",
      "139.61904053684216\n"
     ]
    }
   ],
   "source": [
    "#Feature names\n",
    "string_features = 'DER_mass_MMC,DER_mass_transverse_met_lep,DER_mass_vis,DER_pt_h,DER_deltaeta_jet_jet,DER_mass_jet_jet,DER_prodeta_jet_jet,DER_deltar_tau_lep,DER_pt_tot,DER_sum_pt,DER_pt_ratio_lep_tau,DER_met_phi_centrality,DER_lep_eta_centrality,PRI_tau_pt,PRI_tau_eta,PRI_tau_phi,PRI_lep_pt,PRI_lep_eta,PRI_lep_phi,PRI_met,PRI_met_phi,PRI_met_sumet,PRI_jet_num,PRI_jet_leading_pt,PRI_jet_leading_eta,PRI_jet_leading_phi,PRI_jet_subleading_pt,PRI_jet_subleading_eta,PRI_jet_subleading_phi,PRI_jet_all_pt'\n",
    "features = string_features.split(\",\")\n",
    "dict = {}\n",
    "for ind, feat in enumerate(features):\n",
    "    dict[feat] = ind\n",
    "    \n",
    "#Subgrouping\n",
    "x_0=x[x[:,dict['PRI_jet_num']]==0]\n",
    "x_1=x[x[:,dict['PRI_jet_num']]==1]\n",
    "x_2=x[x[:,dict['PRI_jet_num']]==2]\n",
    "x_3=x[x[:,dict['PRI_jet_num']]==3]\n",
    "y_0=y[x[:,dict['PRI_jet_num']]==0]\n",
    "y_1=y[x[:,dict['PRI_jet_num']]==1]\n",
    "y_2=y[x[:,dict['PRI_jet_num']]==2]\n",
    "y_3=y[x[:,dict['PRI_jet_num']]==3]\n",
    "ids_0=ids[x[:,dict['PRI_jet_num']]==0]\n",
    "ids_1=ids[x[:,dict['PRI_jet_num']]==1]\n",
    "ids_2=ids[x[:,dict['PRI_jet_num']]==2]\n",
    "ids_3=ids[x[:,dict['PRI_jet_num']]==3]\n",
    "x_list = [x_0]\n",
    "x_list.append(x_1)\n",
    "x_list.append(x_2)\n",
    "x_list.append(x_3)\n",
    "ids_list = [ids_0]\n",
    "ids_list.append(ids_1)\n",
    "ids_list.append(ids_2)\n",
    "ids_list.append(ids_3)\n",
    "\n",
    "#Standardization of subgroups\n",
    "mean = []\n",
    "std = []\n",
    "x_nan_replaced = []\n",
    "for i in range(4):\n",
    "    x,m,s = standardize_NAN(x_list[i])\n",
    "    x_nan_replaced.append(replace_mean(x))\n",
    "    mean.append(m)\n",
    "    std.append(s)\n",
    "    \n",
    "#Grouping them back again\n",
    "def group(ls,ids):\n",
    "    data_ord = np.insert(ls[0],0,ids[0], axis=1)\n",
    "    for i in range(1,4):\n",
    "        a = np.insert(ls[i],0,ids[i], axis=1)\n",
    "        data_ord = np.concatenate((data_ord, a))\n",
    "    x_inorder = data_ord[data_ord[:,0].argsort()]\n",
    "    return x_inorder[:,1:]\n",
    "x_inorder = group(x_nan_replaced, ids_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg = remove_rows_by_percentiles(x,x_clean)\n",
    "x_perc = np.delete(x, arg, axis=0)\n",
    "y_perc = np.delete(y, arg, axis=0)\n",
    "\n",
    "selected_columns0 = [1, 2, 3, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 29]\n",
    "selected_columns1 = [1, 2, 3, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 29]\n",
    "selected_columns_ideal = [0, 1, 2, 3, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 29]\n",
    "\n",
    "def selected_non_nan_columns(x):\n",
    "    x_selected = np.zeros((len(x), len(selected_columns0)))\n",
    "    for i in range(len(x)):\n",
    "        s = np.take(x[i], indices=selected_columns0, axis=0)\n",
    "        x_selected[i] = s\n",
    "    return x_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sel = selected_non_nan_columns(x_perc)\n",
    "x_sel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = x_sel != -999\n",
    "v.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_s = x_sel\n",
    "y_s = y_perc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_poly = build_poly(x_s, 2)\n",
    "lambda_ = 0.1\n",
    "w, loss = ridge_regression_s(y_s, x_poly, lambda_)\n",
    "x_poly[:1]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
=======
   "execution_count": null,
>>>>>>> b64f4377a2e22340c55906c3b8b59d4bb046fcf2
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOT RUN\n",
    "indices = build_k_indices(y_s, 4, seed=1)\n",
    "x_test = x_s[indices[0]]\n",
    "x_train = np.delete(x_s, [indices[0]], axis=0)\n",
    "x_train.shape\n",
    "loss_tr, loss_te = cross_validation_rr(y_s, x_s, k_indices=indices, k=1, lambda_=0.1, degree=3)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best lambda is: 0.0002592943797404667\n",
      "Training set mse: 0.6484303176862202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emmal\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:47: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'bool' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-eeb0b08116e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[0my_predicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw_rr_opt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_poly\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m \u001b[0maccuracy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_clean\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0my_predicted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_clean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"accuracy = {val}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'bool' object is not iterable"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> b64f4377a2e22340c55906c3b8b59d4bb046fcf2
   "source": [
    "K=4\n",
    "def cross_validation_demo_RR(x,y,K):\n",
    "    seed = 1\n",
    "    degree = 4\n",
    "    k_fold = K\n",
    "    lambdas = np.logspace(-4, 0, 30)\n",
    "    \n",
    "    # split data in k fold\n",
    "    k_indices = build_k_indices(y, k_fold, seed)\n",
    "    x_test = x[k_indices[0]]\n",
    "    x_train = np.delete(x, [indices[0]], axis=0)\n",
    "    \n",
    "    # define lists to store the loss of training data and test data\n",
    "    rmse_tr = []\n",
    "    rmse_te = []\n",
    "    \n",
    "    for i in range(len(lambdas)):\n",
    "        l = lambdas[i]\n",
    "        avg_err_tr = 0\n",
    "        avg_err_te = 0\n",
    "        for k in range(k_fold):\n",
    "            err = cross_validation_rr(y, x, k_indices, k, l, degree)\n",
    "            avg_err_tr += err[0]\n",
    "            avg_err_te += err[1]\n",
    "        rmse_tr.append(np.sqrt(2 * avg_err_tr / k_fold))\n",
    "        rmse_te.append(np.sqrt(2 * avg_err_te / k_fold))\n",
    "    cross_validation_visualization(lambdas, rmse_tr, rmse_te)\n",
    "    \n",
    "    min_err_index = 0\n",
    "    for i in range(1, len(rmse_te)):\n",
    "        if rmse_te[i] < rmse_te[min_err_index]:\n",
    "            min_err_index = i\n",
    "            \n",
    "    print('Best lambda is: {0}'.format(lambdas[min_err_index]))       \n",
    "    \n",
<<<<<<< HEAD
    "cross_validation_demo_RR(x_s,y_s,4)\n",
=======
    "cross_validation_demo_RR(x_inorder,y,K)\n",
>>>>>>> b64f4377a2e22340c55906c3b8b59d4bb046fcf2
    "\n",
    "degree_opt = 4\n",
    "lambda_opt = 0.0006723357536499335\n",
    "x_poly = build_poly(x_s, degree_opt)\n",
    "w_rr_opt, loss_tr = ridge_regression_s(y_s, x_poly, lambda_opt)\n",
    "print(\"Training set mse: {}\".format(loss_tr))\n",
    "\n",
    "#Training Accuracy\n",
    "y_predicted = predict_labels(w_rr_opt, x_poly)\n",
    "accuracy = []\n",
    "accuracy.append((list(y_clean == y_predicted).count(True))/len(y_clean))\n",
    "print(\"accuracy = {val}\".format(val=accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_factors(x):\n",
    "    # This function takes a number and prints the factors\n",
    "    a = []\n",
    "    for i in range(2,10):\n",
    "        if x % i == 0:\n",
    "            a.append(i)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tX_LS=tX_clean.copy()\n",
    "#y_LS= y_clean.copy()\n",
    "#accuracy=0.7239627683002026 mse=0.7401139564470155\n",
    "\n",
    "#tX_LS=tX_nan.copy()\n",
    "#y_LS= y.copy()\n",
    "# accuracy=0.745088 mse=0.6786542286532609\n",
    "\n",
    "def compute_least_squares(x, y):\n",
    "    x_LS=x.copy()\n",
    "    y_LS= y.copy()\n",
    "\n",
    "    K_values = return_factors(len(x_LS))\n",
    "    accuracy = []\n",
    "    #K-fold crossvalidation\n",
    "    for K in K_values:\n",
    "        #Initialization\n",
    "        list_x_LS = np.split(x_LS,K)\n",
    "        list_y_LS = np.split(y_LS,K)\n",
    "        weights=[]\n",
    "        mse_errors = []\n",
    "        opt_w = []\n",
    "        for ind, x_bloc in enumerate(list_x_LS):\n",
    "            x_test = x_bloc\n",
    "            y_test = list_y_LS[ind]\n",
    "            x_train = np.concatenate(list_x_LS[:ind] + list_x_LS[ind+1:])\n",
    "            y_train = np.concatenate(list_y_LS[:ind] + list_y_LS[ind+1:])\n",
    "            mse_LS, optimal_weights_LS = least_squares(y_train,x_train)\n",
    "            mse_errors.append(compute_mse(y_test, x_test, optimal_weights_LS))\n",
    "            weights.append(optimal_weights_LS)\n",
    "\n",
    "        opt_w = weights[np.argmin(mse_errors)]\n",
    "        y_model = predict_labels(opt_w, x_LS)\n",
    "\n",
    "        #Computing accuracy\n",
    "        accuracy.append((list(y_model == y_LS).count(True))/len(y_model))\n",
    "        print(\"accuracy = {val} mse={mse}\".format(mse = mse_LS, val=accuracy[-1]))\n",
    "\n",
    "    #Plot of accuracies\n",
    "    print(\"\\nMaximum accuracy = {val}\".format(val=np.max(accuracy)))\n",
    "    #plt.plot(K_values, accuracy, '.-', markersize=15, label = \"Accuracy\");\n",
    "    #plt.xlabel(\"K value\")\n",
    "    #plt.ylabel(\"Accuracy\")\n",
    "    #plt.title(\"Accuracies for Least Squares\")\n",
    "    #plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.339992 mse=0.16916771391528657\n",
      "accuracy = 0.339944 mse=0.1693944515525672\n",
      "accuracy = 0.339952 mse=0.16935851609831304\n",
      "accuracy = 0.339924 mse=0.16936699783814213\n",
      "\n",
      "Maximum accuracy = 0.339992\n"
     ]
    }
   ],
   "source": [
    "compute_least_squares(x_inorder, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Least squares gradient descent"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We can alter on gamma + w_initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def cross_validation_LS_GD_demo(x_LS,y_LS,K): \n",
    "    #Adding constant term\n",
    "    tX_LS = np.c_[np.ones((y_LS.shape[0], 1)), x_LS]\n",
    "\n",
    "    max_iters = 100\n",
    "    gammas = np.logspace(-4,0,20)\n",
    "\n",
    "\n",
    "    # Initialization\n",
    "    w_initial = np.zeros(tX_LS.shape[1])\n",
    "\n",
    "    list_tX_LS = np.split(tX_LS,K)\n",
    "    list_y_LS = np.split(y_LS,K)\n",
    "\n",
    "    gen_opt_w=[]\n",
    "    gen_mse =[]\n",
    "\n",
    "    #gamma selection\n",
    "    for ind, gamma in enumerate(gammas):\n",
    "        weights=[]\n",
    "        mse_errors = []\n",
    "        #K-fold crossvalidation\n",
    "        for ind, tX_bloc in enumerate(list_tX_LS):\n",
    "            tX_test = tX_bloc\n",
    "            y_test = list_y_LS[ind]\n",
    "            tX_train= list_tX_LS[:ind] + list_tX_LS[ind+1:]\n",
    "            tX_train= np.concatenate(tX_train)\n",
    "            y_train= list_y_LS[:ind] + list_y_LS[ind+1:]\n",
    "            y_train=np.concatenate(y_train)\n",
    "        \n",
    "            mse, opt_w = least_squares_GD(y_train, tX_train, w_initial, max_iters, gamma)\n",
    "            mse_errors.append(compute_mse(y_test, tX_test,opt_w))\n",
    "            weights.append(opt_w)\n",
    "        gen_mse.append(np.mean(mse_errors))\n",
    "        gen_opt_w.append(np.mean(weights, axis=0))\n",
    "    optimal_gamma_LS_GD = gammas[np.nanargmin(gen_mse)]\n",
    "    optimal_weights_LS_GD = gen_opt_w[np.nanargmin(gen_mse)]\n",
    "    mse_LS_GD = np.nanmin(gen_mse)\n",
    "    print(\" gamma={l:.3f},mse={mse:.3f}\".format(mse = mse_LS_GD, l = optimal_gamma_LS_GD))\n",
    "\n",
    "    #Training Accuracy\n",
    "    y_predicted = predict_labels(optimal_weights_LS_GD, tX_LS)\n",
    "    accuracy = []\n",
    "    accuracy.append((list(y_LS == y_predicted).count(True))/len(y_LS))\n",
    "    print(accuracy)\n",
    "    #return accuracy,optimal_gamma_LS_GD, optimal_wights_LS_GD,mse_LS_GD\n"
   ]
  },
  {
<<<<<<< HEAD
=======
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#With tX and y_LS no corrupted\n",
    "print(\"dataset1\")\n",
    "x_LS, m_X,s = standardize(x_clean.copy())\n",
    "x_LS = x_LS[0:68110]\n",
    "y_LS = y_clean[0:68110].copy()\n",
    "cross_validation_LS_GD_demo(x_LS,y_LS,5)\n",
    "\n",
    "#With nan value replaced\n",
    "print(\"dataset2\")\n",
    "x_LS=x_nan.copy()\n",
    "y_LS=y.copy()\n",
    "cross_validation_LS_GD_demo(x_LS,y_LS,5)\n",
    "#With x_te\n",
    "print(\"dataset3\")\n",
    "x_LS =x_s\n",
    "y_LS=y_s\n",
    "cross_validation_LS_GD_demo(x_LS,y_LS,4)\n",
    "#Data subgoup\n",
    "x_LS = x_inorder\n",
    "y_LS =y.copy()\n",
    "cross_validation_LS_GD_demo(x_LS,y_LS,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data subgoup\n",
    "x_LS = x_inorder\n",
    "y_LS =y.copy()\n",
    "cross_validation_LS_GD_demo(x_LS,y_LS,5)"
   ]
  },
  {
>>>>>>> b64f4377a2e22340c55906c3b8b59d4bb046fcf2
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Least square SDG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can alter the gamma and the batch size"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 15,
=======
   "execution_count": null,
>>>>>>> b64f4377a2e22340c55906c3b8b59d4bb046fcf2
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_LS_SGD_demo(x_LS,y_LS,K):\n",
    "    #Adding constant term\n",
    "    tX_LS = np.c_[np.ones((y_LS.shape[0], 1)), x_LS]\n",
    "\n",
    "    max_iters = 50\n",
    "    max_batch_size = 32\n",
    "    gammas = np.logspace(-4,0,20)\n",
    "    batch_sizes = np.array([2,4,6,8])\n",
    "\n",
    "    # Initialization\n",
    "    w_initial = np.zeros(tX_LS.shape[1])\n",
    "    list_tX_LS = np.split(tX_LS,K)\n",
    "    list_y_LS = np.split(y_LS,K)\n",
    "\n",
    "\n",
    "    result_mse =[]\n",
    "    result_opt_w=[]\n",
    "    result_gamma=[]\n",
    "    for ind_batch,batch_size in enumerate(batch_sizes):  \n",
    "        result_mse_gamma = []\n",
    "        result_opt_w_gamma = []\n",
    "        for ind_gamma,gamma in enumerate(gammas):\n",
    "            mse_errors=[]\n",
    "            weights=[]\n",
    "            #K-fold crossvalidation\n",
    "            for ind, tX_bloc in enumerate(list_tX_LS):\n",
    "                tX_test = tX_bloc\n",
    "                y_test = list_y_LS[ind]\n",
    "                tX_train= list_tX_LS[:ind] + list_tX_LS[ind+1:]\n",
    "                tX_train= np.concatenate(tX_train)\n",
    "                y_train= list_y_LS[:ind] + list_y_LS[ind+1:]\n",
    "                y_train=np.concatenate(y_train)\n",
    "        \n",
    "                sgd_mse, opt_w = least_squares_SGD(y_train, tX_train, w_initial, batch_size, max_iters, gamma)\n",
    "                mse_errors.append(compute_mse(y_test, tX_test,opt_w))\n",
    "                weights.append(opt_w)\n",
    "    \n",
    "            result_mse_gamma.append(np.mean(mse_errors))\n",
    "            result_opt_w_gamma.append(np.mean(weights,axis=0))\n",
    "        result_mse.append(np.min(result_mse_gamma))\n",
    "        result_gamma.append(gammas[np.argmin(result_mse_gamma)])\n",
    "        result_opt_w.append(result_opt_w_gamma[np.argmin(result_mse_gamma)])\n",
    "\n",
    "    print(\" gamma={l:.3f}, batch={b:.2f}, mse={mse:.3f}\".format(mse = np.nanmin(result_mse), l =result_gamma[np.nanargmin(result_mse)], b=np.nanargmin(result_mse)))\n",
    "\n",
    "    optimal_weights_LS_SGD = result_opt_w[np.nanargmin(result_mse)]\n",
    "    \n",
    "\n",
    "    #Training Accuracy\n",
    "    y_predicted = predict_labels(optimal_weights_LS_SGD, tX_LS)\n",
    "    accuracy = []\n",
    "    accuracy.append((list(y_LS == y_predicted).count(True))/len(y_LS))\n",
    "    print(accuracy)\n",
    "\n",
    "#With tX_CLEAN : accuracy = , mse= , gamma = , batch=\n",
    "#With tX_NAN : accuracy= , mse= , gamma = ,batch=\n",
    "\n"
   ]
  },
  {
<<<<<<< HEAD
=======
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#With tX and y_LS no corrupted\n",
    "print(\"dataset1\")\n",
    "x_LS, m_X,s = standardize(x_clean.copy())\n",
    "x_LS = x_LS[0:68110]\n",
    "y_LS = y_clean[0:68110].copy()\n",
    "#cross_validation_LS_SGD_demo(x_LS,y_LS,5)\n",
    "#With nan value replaced\n",
    "print(\"dataset2\")\n",
    "x_LS=x_nan.copy()\n",
    "y_LS=y.copy()\n",
    "cross_validation_LS_SGD_demo(x_LS,y_LS,5)\n",
    "#With x_te\n",
    "print(\"dataset3\")\n",
    "x_LS =x_s\n",
    "y_LS=y_s\n",
    "cross_validation_LS_SGD_demo(x_LS,y_LS,4)"
   ]
  },
  {
>>>>>>> b64f4377a2e22340c55906c3b8b59d4bb046fcf2
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression (not regularized)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 16,
=======
   "execution_count": null,
>>>>>>> b64f4377a2e22340c55906c3b8b59d4bb046fcf2
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def cross_validation_LR_demo(x_LR,y_LR,K):\n",
    "\n",
    "    #Adding constant term\n",
    "    tX_LR = np.c_[np.ones((y_LR.shape[0], 1)), x_LR]\n",
    "    max_iters = 100\n",
    "    gammas = np.logspace(-4,0,20)\n",
    "\n",
    "    # Initialization\n",
    "    w_initial = np.zeros(tX_LR.shape[1])\n",
    "\n",
    "    list_tX_LR = np.split(tX_LR,K)\n",
    "    list_y_LR = np.split(y_LR,K)\n",
    "\n",
    "    gen_opt_w=[]\n",
    "    gen_loss =[]\n",
    "\n",
    "    #gamma selection\n",
    "    for ind, gamma in enumerate(gammas):\n",
    "        weights=[]\n",
    "        loss_errors = []\n",
    "        #K-fold crossvalidation\n",
    "        for ind, tX_bloc in enumerate(list_tX_LR):\n",
    "            tX_test = tX_bloc\n",
    "            y_test = list_y_LR[ind]\n",
    "            tX_train= list_tX_LR[:ind] + list_tX_LR[ind+1:]\n",
    "            tX_train= np.concatenate(tX_train)\n",
    "            y_train= list_y_LR[:ind] + list_y_LR[ind+1:]\n",
    "            y_train=np.concatenate(y_train)\n",
    "            loss, opt_w = logistic_regression(y_train,tX_train,w_initial, max_iters, gamma)\n",
    "            loss_errors.append(calculate_loss_logistic_reg(y_test, tX_test,opt_w))\n",
    "            weights.append(opt_w)\n",
    "        gen_loss.append(np.mean(loss_errors))\n",
    "        gen_opt_w.append(np.mean(weights, axis=0))\n",
    "\n",
    "\n",
    "    optimal_gamma_LR = gammas[np.nanargmin(gen_loss)]\n",
    "    optimal_weights_LR = gen_opt_w[np.nanargmin(gen_loss)]\n",
    "    print(\" gamma={l:.3f},loss={loss:.3f}\".format(loss = np.min(gen_loss), l = optimal_gamma_LR))\n",
    "\n",
    "\n",
    "     #Training Accuracy\n",
    "    y_predicted = predict_labels(optimal_weights_LR, tX_LR)\n",
    "    accuracy = []\n",
    "    accuracy.append((list(y_LR == y_predicted).count(True))/len(y_LR))\n",
    "    print(accuracy)\n",
    "\n",
    "#With tX_CLEAN : accuracy = 0.6823, loss= , gamma = \n",
    "#With tX_NAN : accuracy= 0.34, loss= nan, gamma = 0.114\n",
    "#With x_te_s : accuracy = 0.7015, loss = 16775, gamma = 0.144"
   ]
  },
  {
<<<<<<< HEAD
=======
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#With tX and y_LS no corrupted\n",
    "print(\"dataset1\")\n",
    "x_LS, m_X,s = standardize(x_clean.copy())\n",
    "x_LS = x_LS[0:68110]\n",
    "y_LS = y_clean[0:68110].copy()\n",
    "cross_validation_LR_demo(x_LS,y_LS,5)\n",
    "\n",
    "#With nan value replaced\n",
    "print(\"dataset2\")\n",
    "x_LS=x_nan.copy()\n",
    "y_LS=y.copy()\n",
    "cross_validation_LR_demo(x_LS,y_LS,5)\n",
    "#With x_te\n",
    "print(\"dataset3\")\n",
    "x_LS =x_s\n",
    "y_LS=y_s\n",
    "cross_validation_LR_demo(x_LS,y_LS,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data subgoup\n",
    "x_LS = x_inorder\n",
    "y_LS =y.copy()\n",
    "cross_validation_LR_demo(x_LS,y_LS,5)"
   ]
  },
  {
>>>>>>> b64f4377a2e22340c55906c3b8b59d4bb046fcf2
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression regularized with lambda"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 17,
=======
   "execution_count": null,
>>>>>>> b64f4377a2e22340c55906c3b8b59d4bb046fcf2
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_LRR_demo(x_LRR,y_LRR,K):\n",
    "    #Adding constant term\n",
    "    tX_LRR = np.c_[np.ones((y_LRR.shape[0], 1)), x_LRR]\n",
    "\n",
    "    max_iters = 50\n",
    "    lambdas = np.logspace(-4,0,10)\n",
    "    gammas = np.logspace(-4,0,20)\n",
    "\n",
    "    # Initialization\n",
    "    w_initial = np.zeros(tX_LRR.shape[1])\n",
    "    list_tX_LRR = np.split(tX_LRR,K)\n",
    "    list_y_LRR = np.split(y_LRR,K)\n",
    "\n",
    "\n",
    "    result_loss =[]\n",
    "    result_opt_w=[]\n",
    "    result_gamma=[]\n",
    "    for ind,lambda_ in enumerate(lambdas):  \n",
    "        result_loss_gamma = []\n",
    "        result_opt_w_gamma = []\n",
    "        for ind_gamma,gamma in enumerate(gammas):\n",
    "            loss_errors=[]\n",
    "            weights=[]\n",
    "            #K-fold crossvalidation\n",
    "            for ind, tX_bloc in enumerate(list_tX_LRR):\n",
    "                tX_test = tX_bloc\n",
    "                y_test = list_y_LRR[ind]\n",
    "                tX_train= list_tX_LRR[:ind] + list_tX_LRR[ind+1:]\n",
    "                tX_train= np.concatenate(tX_train)\n",
    "                y_train= list_y_LRR[:ind] + list_y_LRR[ind+1:]\n",
    "                y_train=np.concatenate(y_train)\n",
    "        \n",
    "                loss, opt_w = reg_logistic_regression(y_train,tX_train,lambda_,w_initial,max_iters,gamma)\n",
    "                loss_errors.append(calculate_loss_logistic_reg(y_test, tX_test,opt_w))\n",
    "                weights.append(opt_w)\n",
    "    \n",
    "            result_loss_gamma.append(np.mean(loss_errors))\n",
    "            result_opt_w_gamma.append(np.mean(weights,axis=0))\n",
    "        result_loss.append(np.min(result_loss_gamma))\n",
    "        result_gamma.append(np.argmin(result_loss_gamma))\n",
    "        result_opt_w.append(result_opt_w_gamma[np.argmin(result_loss_gamma)])\n",
    "\n",
    "    print(np.min(result_loss))\n",
    "    print(result_gamma[np.argmin(result_loss)])\n",
    "    print(np.argmin(result_loss))\n",
    "    print(\" gamma={l:.3f}, batch={b:.0f}, mse={mse:.3f}\".format(mse = np.min(result_loss), l =result_gamma[np.argmin(result_loss)], b=np.argmin(result_loss)))\n",
    "\n",
    "    optimal_weights_LRR = result_opt_w[np.argmin(result_loss)]\n",
    "    print(optimal_weights_LRR)\n",
    "\n",
    "    #Training Accuracy\n",
    "    y_predicted = predict_labels(optimal_weights_LRR, tX_LRR)\n",
    "    accuracy = []\n",
    "    accuracy.append((list(y_LRR == y_predicted).count(True))/len(y_LRR))\n",
    "    print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST PART"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset1\n",
      "134.10663740969926\n",
      "Regularized Logistic Regression\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-8017622f6954>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_clean\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m68110\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Regularized Logistic Regression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mcross_validation_LRR_demo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Logistic Regression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mcross_validation_LR_demo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-0f75bf305d49>\u001b[0m in \u001b[0;36mcross_validation_LRR_demo\u001b[1;34m(x_LRR, y_LRR, K)\u001b[0m\n\u001b[0;32m     31\u001b[0m                 \u001b[0my_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m                 \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt_w\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreg_logistic_regression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlambda_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw_initial\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_iters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m                 \u001b[0mloss_errors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcalculate_loss_logistic_reg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mopt_w\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m                 \u001b[0mweights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopt_w\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\Cours M1 S1\\Machine Learning\\ML_course-master\\ML_course\\projects\\project1\\scripts\\implementations.py\u001b[0m in \u001b[0;36mreg_logistic_regression\u001b[1;34m(y, tx, lambda_, initial_w, max_iters, gamma)\u001b[0m\n\u001b[0;32m    170\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0miter\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_iters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mcalculate_loss_logistic_reg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mlambda_\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m         \u001b[0mgradient\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mcompute_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlambda_\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m         \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[1;31m# converge criterion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\Cours M1 S1\\Machine Learning\\ML_course-master\\ML_course\\projects\\project1\\scripts\\implementations.py\u001b[0m in \u001b[0;36mcompute_gradient\u001b[1;34m(y, tx, w)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcompute_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;34m\"\"\"Compute the gradient.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0me\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m-\u001b[0m \u001b[0mtx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mcoef\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mtx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcoef\u001b[0m\u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> b64f4377a2e22340c55906c3b8b59d4bb046fcf2
   "source": [
    "#With tX and y_LS no corrupted\n",
    "print(\"dataset1\")\n",
    "x, m_X,s = standardize(x_clean.copy())\n",
    "x = x[0:68110]\n",
    "y = y_clean[0:68110].copy()\n",
    "print(\"Regularized Logistic Regression\")\n",
    "cross_validation_LRR_demo(x,y,5)\n",
    "print(\"Logistic Regression\")\n",
    "cross_validation_LR_demo(x,y,5)\n",
    "print(\"Least-Square -SDG\")\n",
    "cross_validation_LS_SGD_demo(x,y,5)\n",
    "print(\"Least-Square -GD\")\n",
    "cross_validation_LS_GD_demo(x,y,5)\n",
    "print(\"Ridge Regression\")\n",
    "cross_validation_demo_RR(x,y,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset2\n",
      "Regularized Logistic Regression\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-fa700550ffeb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Regularized Logistic Regression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mcross_validation_LRR_demo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Logistic Regression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mcross_validation_LR_demo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-0f75bf305d49>\u001b[0m in \u001b[0;36mcross_validation_LRR_demo\u001b[1;34m(x_LRR, y_LRR, K)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcross_validation_LRR_demo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_LRR\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_LRR\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m#Adding constant term\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mtX_LRR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_LRR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_LRR\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mmax_iters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\index_tricks.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    333\u001b[0m                 \u001b[0mobjs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobjs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 335\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
     ]
    }
   ],
   "source": [
    "#With nan value replaced\n",
    "print(\"dataset2\")\n",
    "x=x_nan.copy()\n",
    "y=y.copy()\n",
    "print(\"Regularized Logistic Regression\")\n",
    "cross_validation_LRR_demo(x,y,5)\n",
    "print(\"Logistic Regression\")\n",
    "cross_validation_LR_demo(x,y,5)\n",
    "print(\"Least-Square -SDG\")\n",
    "cross_validation_LS_SGD_demo(x,y,5)\n",
    "print(\"Least-Square -GD\")\n",
    "cross_validation_LS_GD_demo(x,y,5)\n",
    "print(\"Ridge Regression\")\n",
    "cross_validation_demo_RR(x,y,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset3\n",
      "Regularized Logistic Regression\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-3e7499fdef28>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0my_s\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Regularized Logistic Regression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mcross_validation_LRR_demo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Logistic Regression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mcross_validation_LR_demo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-0f75bf305d49>\u001b[0m in \u001b[0;36mcross_validation_LRR_demo\u001b[1;34m(x_LRR, y_LRR, K)\u001b[0m\n\u001b[0;32m     31\u001b[0m                 \u001b[0my_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m                 \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt_w\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreg_logistic_regression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlambda_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw_initial\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_iters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m                 \u001b[0mloss_errors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcalculate_loss_logistic_reg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mopt_w\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m                 \u001b[0mweights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopt_w\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\Cours M1 S1\\Machine Learning\\ML_course-master\\ML_course\\projects\\project1\\scripts\\implementations.py\u001b[0m in \u001b[0;36mreg_logistic_regression\u001b[1;34m(y, tx, lambda_, initial_w, max_iters, gamma)\u001b[0m\n\u001b[0;32m    170\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0miter\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_iters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mcalculate_loss_logistic_reg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mlambda_\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m         \u001b[0mgradient\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mcompute_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlambda_\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m         \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[1;31m# converge criterion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\Cours M1 S1\\Machine Learning\\ML_course-master\\ML_course\\projects\\project1\\scripts\\implementations.py\u001b[0m in \u001b[0;36mcompute_gradient\u001b[1;34m(y, tx, w)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcompute_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;34m\"\"\"Compute the gradient.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0me\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m-\u001b[0m \u001b[0mtx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mcoef\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mtx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcoef\u001b[0m\u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#With x_te\n",
    "print(\"dataset3\")\n",
    "x =x_s.copy()\n",
    "y =y_s.copy()\n",
    "print(\"Regularized Logistic Regression\")\n",
    "cross_validation_LRR_demo(x,y,4)\n",
    "print(\"Logistic Regression\")\n",
    "cross_validation_LR_demo(x,y,4)\n",
    "print(\"Least-Square -SDG\")\n",
    "cross_validation_LS_SGD_demo(x,y,4)\n",
    "print(\"Least-Square -GD\")\n",
    "cross_validation_LS_GD_demo(x,y,4)\n",
    "print(\"Ridge Regression\")\n",
    "cross_validation_demo_RR(x,y,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv/test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = './logisticRegression_x_te_s' # TODO: fill in desired name of output file for submission\n",
    "tX_test = np.c_[np.ones((tX_test.shape[0], 1)), tX_test]\n",
    "tX_test = selected_non_nan_columns(tX_test)\n",
    "y_pred = predict_labels(optimal_weights_LR, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
